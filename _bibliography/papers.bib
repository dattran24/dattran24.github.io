---
---

@string{aps = {American Physical Society,}}


@article{klmtneurips,
  abbr={Conference},
  title={Fundamental Convergence Analysis of Sharpness-Aware Minimization},
  author={Khanh*, P. D. and Luong, H-C and Mordukhovich*, B. S. and Tran*â€ , D.B},
  abstract={The paper investigates the fundamental convergence properties of Sharpness-Aware Minimization (SAM), a recently proposed gradient-based optimization method (Foret et al., 2021) that significantly improves the generalization of deep neural networks. The convergence properties including the stationarity of accumulation points, the convergence of the sequence of gradients to the origin, the sequence of function values to the optimal value, and the sequence of iterates to the optimal solution are established for the method. The universality of the provided convergence analysis based on inexact gradient descent frameworks (Khanh et al., 2023b) allows its extensions to the normalized versions of SAM such as VaSSO (Li & Giannakis, 2023), RSAM (Liu et al., 2022), and to the unnormalized versions of SAM such as USAM (Andriushchenko & Flammarion, 2022). Numerical experiments are conducted on classification tasks using deep learning models to confirm the practical aspects of our analysis.},
  journal={to appear Advances in Neural Information Processing Systems},
  year={2024},
  month={September},
  publisher=aps,
  doi={},
  url={https://arxiv.org/abs/2401.08060},
  html={https://neurips.cc/},
  pdf={SAM_Neurips.pdf},
  altmetric={},
  dimensions={true},
  google_scholar_id={W7OEmFMy1HYC},
  video={},
  selected={true},
}
@article{kmptMAPR,
  abbr={Journal},
  title={Globally convergent coderivative-based generalized Newton methods in nonsmooth optimization},
  author={PD Khanh, BS Mordukhovich, VT Phat, DB Tran},
  journal={Mathematical Programming},
  volume={205},
  pages={373-429},
  year={2024}
}

@article{kmptJOGO,
  abbr={Journal},
  title={Generalized damped Newton algorithms in nonsmooth optimization via second-order subdifferentials},
  author={PD Khanh, BS Mordukhovich, VT Phat, DB Tran},
  journal={Journal of Global Optimization},
  volume={86},
  pages={93-122},
  year={2023}
}

@article{kmtJOTA,
  abbr={Journal},
  title={Inexact reduced gradient methods in nonconvex optimization},
  author={PD Khanh, BS Mordukhovich, DB Tran},
  journal={Journal of Optimization Theory and Applications},
  pages={1-41},
  year={2023}
}

@article{kmtOMS,
  abbr={Journal},
  title={A new inexact gradient descent method with applications to nonsmooth convex optimization},
  author={PD Khanh, BS Mordukhovich, DB Tran},
  journal={Optimization Methods and Software},
  abstract={sadas},
  html={https://www.tandfonline.com/doi/full/10.1080/10556788.2024.2322700},
  pdf={example_pdf.pdf},
  pages={1-29},
  year={2024}
}

@article{kmptJOGOprox,
  abbr={Journal},
  bibtex_show={true},
  title={Inexact proximal methods for weakly convex functions},
  author={PD Khanh and BS Mordukhovich and VT Phat and DB Tran},
  journal={to appear Journal of Global Optimization},
  url={https://arxiv.org/pdf/2307.15596},
  year={2024}
}

@article{kmtMAPR,
  abbr={Preprint},
  bibtex_show={true},
  title={Globally Convergent Derivative-Free Methods in Nonconvex Optimization with and without Noise},
  author={PD Khanh, BS Mordukhovich, DB Tran},
  url={https://optimization-online.org/?p=26889},
  year={2024}
}
@article{ckmtMAPR,
  abbr={Preprint},
  bibtex_show={true},
  title={Local Convergence Analysis for Nonisolated Solutions to Derivative-Free Methods of Optimization},
  author={DH Cuong, PD Khanh, BS Mordukhovich, DB Tran},
  url={https://optimization-online.org/?p=27216},
  year={2024}
}