{
  "basics": {
    "name": "Dat Ba Tran",
    "label": "Ph.D. Student",
    "image": "",
    "email": "tranbdat@wayne.edu",
    "url": "https://he9180.github.io/",
    "location": {
      "address": "1252 FAB, 646 W Kirby",
      "postalCode": "MI 48202",
      "city": "Detroit",
      "countryCode": "US",
      "region": "MidWest"
    },
    "profiles": [
      {
        "network": "LinkedIn",
        "username": "Dat Tran",
        "url": "https://twitter.com/dat-tran-4b778a202"
      }
    ]
  },
  "work": [
    {
      "name": "Department of Mathematics, Wayne State University",
      "position": "Graduate Research and Teaching Assistant",
      "url": "https://clasprofiles.wayne.edu/profile/he9180",
      "startDate": "2020-08-20",
      "summary": "Teaching at Wayne State University involves preparing and delivering lectures, grading assignments to ensure a solid understanding of course materials. Conducting research focuses on mathematical optimization, machine learning and artificial intelligence"
    }
  ],
  "conf": [
    {
      "organization": "SIAM Great Lakes Section Annual Meeting",
      "location": "Detroit, Michigan",
      "position": "Co-organizer",
      "url": "https://hli.wayne.edu/conferences/glsiam2022/main.html",
      "startDate": "2014-04-01",
      "endDate": "2015-07-01",
      "summary": "Designing registration platforms, communicating with speakers, and organizing talks."
    }
  ],
  "education": [
    {
      "institution": "Wayne State University, Detroit",
      "location": "Michigan, USA",
      "url": "https://wayne.edu/",
      "area": "Applied Mathematics",
      "studyType": "PhD",
      "startDate": "2020-08-20",
      "score": "10",
      "courses": ["Thesis: Inexact First-order Methods in Convex and Nonconvex Optimization"]
    }
  ],
  "awards": [
    {
      "title": "Robert and Nancy Irvan Endowed Scholarship in Mathematics",
      "date": "2024",
      "awarder": "Wayne State University",
      "summary": "Recognizing Outstanding Academic Achievements."
    }
  ],
  "certificates": [
    {
      "name": "Machine Learning",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-location-dot"
    },
    {
      "name": "Quantum Computing",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-tag"
    },
    {
      "name": "Quantum Information",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-envelope"
    },
    {
      "name": "Quantum Cryptography",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-hashtag"
    },
    {
      "name": "Quantum Communication",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-calendar"
    },
    {
      "name": "Quantum Teleportation",
      "date": "2018-01-01",
      "issuer": "Stanford University",
      "url": "https://example.com",
      "icon": "fa-solid fa-clipboard-check"
    }
  ],
  "publications": [
    {
      "name": "Fundamental Convergence Analysis of Sharpness-Aware Minimization",
      "publisher": "Advances in Neural Information Processing Systems",
      "releaseDate": "2024",
      "url": "https://arxiv.org/abs/2401.08060",
      "summary": "The paper investigates the fundamental convergence properties of Sharpness-Aware Minimization (SAM), a gradient-based optimization method that enhances the generalization of deep neural networks. It establishes convergence properties such as stationarity of accumulation points and convergence of gradients to the optimal value, with extensions to various normalized and unnormalized versions of SAM."
    },
    {
      "name": "Globally convergent coderivative-based generalized Newton methods in nonsmooth optimization",
      "publisher": "Mathematical Programming",
      "releaseDate": "2024",
      "url": "https://link.springer.com/article/10.1007/s10107-023-01980-2",
      "summary": "This paper proposes two globally convergent Newton-type methods for nonsmooth optimization problems using coderivatives and generalized Hessians. The methods extend the damped Newton method and regularized Newton type algorithms, achieving linear and superlinear convergence rates. Numerical experiments validate the performance of the new algorithms against established methods."
    },
    {
      "name": "Generalized damped Newton algorithms in nonsmooth optimization via second-order subdifferentials",
      "publisher": "Journal of Global Optimization",
      "releaseDate": "2023",
      "url": "https://link.springer.com/article/10.1007/s10898-022-01248-7",
      "summary": "This paper develops globally convergent generalized damped Newton algorithms for solving nonsmooth optimization problems using second-order subdifferentials. The authors present numerical results demonstrating the effectiveness of their algorithm on Lasso problems compared to other optimization techniques."
    },
    {
      "name": "Inexact reduced gradient methods in nonconvex optimization",
      "publisher": "Journal of Optimization Theory and Applications",
      "releaseDate": "2023",
      "url": "https://link.springer.com/article/10.1007/s10957-023-02319-9",
      "summary": "The paper presents new linesearch methods using inexact gradient information to find stationary points in nonconvex optimization. It establishes convergence results under the Kurdyka-Lojasiewicz property and demonstrates advantages of automatically controlled errors in the proposed methods through numerical experiments."
    },
    {
      "name": "A new inexact gradient descent method with applications to nonsmooth convex optimization",
      "publisher": "Optimization Methods and Software",
      "releaseDate": "2024",
      "url": "https://www.tandfonline.com/doi/full/10.1080/10556788.2024.2322700",
      "summary": "This paper introduces a novel inexact gradient descent method for minimizing C1-smooth functions with Lipschitzian gradients. The authors demonstrate convergence of iterates to stationary points and apply the method to develop two novel gradient-based methods for nonsmooth convex optimization, supported by numerical experiments."
    },
    {
      "name": "Inexact proximal methods for weakly convex functions",
      "publisher": "Journal of Global Optimization",
      "releaseDate": "2024",
      "url": "https://arxiv.org/pdf/2307.15596",
      "summary": "The paper develops inexact proximal methods for finding stationary points of the sum of a smooth function and a nonsmooth weakly convex function. The methods achieve global convergence with constructive rates under the Kurdyka-Lojasiewicz property, supported by convergence analysis."
    },
    {
      "name": "Globally Convergent Derivative-Free Methods in Nonconvex Optimization with and without Noise",
      "publisher": "Preprint",
      "releaseDate": "2024",
      "url": "https://optimization-online.org/?p=26889",
      "summary": "This paper addresses nonconvex derivative-free optimization problems, proposing methods for minimizing functions with globally Lipschitz continuous gradients. It guarantees convergence under both noiseless and noisy conditions and presents numerical experiments demonstrating the robustness of the proposed algorithms."
    },
    {
      "name": "Local Convergence Analysis for Nonisolated Solutions to Derivative-Free Methods of Optimization",
      "publisher": "Preprint",
      "releaseDate": "2024",
      "url": "https://optimization-online.org/?p=27216",
      "summary": "This paper investigates local convergence properties of derivative-free optimization methods for nonisolated solutions, providing theoretical insights into their performance."
    }
  ],
  "skills": [
    {
      "name": "Physics",
      "level": "Master",
      "icon": "fa-solid fa-hashtag",
      "keywords": [
        "Quantum Mechanics",
        "Quantum Computing",
        "Quantum Information",
        "Quantum Cryptography",
        "Quantum Communication",
        "Quantum Teleportation"
      ]
    }
  ],
  "languages": [
    {
      "language": "German",
      "fluency": "Native speaker",
      "icon": ""
    },
    {
      "language": "English",
      "fluency": "Fluent",
      "icon": ""
    }
  ],
  "interests": [
    {
      "name": "Physics",
      "icon": "fa-solid fa-tag",
      "keywords": [
        "Quantum Mechanics",
        "Quantum Computing",
        "Quantum Information",
        "Quantum Cryptography",
        "Quantum Communication",
        "Quantum Teleportation"
      ]
    }
  ],
  "references": [
    {
      "name": "Professor Boris Mordukhovich",
      "icon": "fa-solid fa-laptop",
      "reference": "PhD advisor"},
    {
      "name": "Doctor Pham Duy Khanh",
      "icon": "fa-solid fa-thumbtack",
      "reference": "PhD advisor"}
  ],
  "projects": [
    {
      "name": "Quantum Computing",
      "summary": "Quantum computing is the use of quantum-mechanical phenomena such as superposition and entanglement to perform computation. Computers that perform quantum computations are known as quantum computers.",
      "highlights": ["Quantum Teleportation", "Quantum Cryptography"],
      "startDate": "2018-01-01",
      "endDate": "2018-01-01",
      "url": "https://example.com"
    }
  ]
}
